{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953b9301",
   "metadata": {},
   "source": [
    "# Data Cleaning Error Log for APS Data\n",
    "### Run Script in Jupyter and scroll to the end to get full error log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da491d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime \n",
    "import re\n",
    "\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "spell.word_frequency.load_text_file('./streetdict.txt')\n",
    "spell.word_frequency.load_text_file('./customdict.txt')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509fd10",
   "metadata": {},
   "source": [
    "#### Import Excel File\n",
    "##### Make sure excel is in the same directory as the project, is named 'accessible-pedestrian-signals.xlsx' and has 3 columns tittled \"Location\", \"Borough\" and \"Date Installed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel file\n",
    "df = pd.read_excel('accessible-pedestrian-signals.xlsx')\n",
    "# Match pandas dataframe index with Excel row\n",
    "df.index = df.index + 2\n",
    "# print DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fff57",
   "metadata": {},
   "source": [
    "---\n",
    "## Rows with missing data\n",
    "#### Will be empty if no data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_errors = df[df.isna().any(axis=1)]\n",
    "null_errors['Error'] =  'Missing Data'\n",
    "null_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bcdb1",
   "metadata": {},
   "source": [
    "---\n",
    "## Rows with duplicate data\n",
    "#### Will be empty if no data is duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data = df[df.duplicated()] \n",
    "duplicate_data['Error'] = ' Duplicate Data'\n",
    "duplicate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c54a6",
   "metadata": {},
   "source": [
    "---\n",
    "## Date Column Error Checking\n",
    "#### Return all entries that have an invalid date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove missing rows\n",
    "df2 = df.dropna(subset = ['Date Installed'])\n",
    "\n",
    "date_errors = df2['Date Installed'] = pd.to_datetime(df2['Date Installed'], errors='coerce')\n",
    "date_errors = df2.loc[df2['Date Installed'].isnull()]\n",
    "date_errors['Error'] = 'Date is invalid'\n",
    "\n",
    "date_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52a855",
   "metadata": {},
   "source": [
    "---\n",
    "## Borough Column Error Checking\n",
    "#### Return all entries that have an invalid borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027ac17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove missing rows\n",
    "df3 = df.dropna(subset = ['Borough'])\n",
    "\n",
    "borough_errors = df3.loc[(df3['Borough'] != 'Brooklyn') & (df3['Borough'] != 'Queens') \n",
    "       & (df3['Borough'] != 'the Bronx') & (df3['Borough'] != 'Bronx')\n",
    "                       & (df3['Borough'] != 'Manhattan') & (df3['Borough'] != 'Staten Island')]\n",
    "\n",
    "borough_errors['Error'] = 'Borough spelling, capitalization or type'\n",
    "\n",
    "borough_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8000ba7",
   "metadata": {},
   "source": [
    "---\n",
    "## Location Column Error Checking\n",
    "\n",
    "### Abbreviations checked for consistency:\n",
    "#### St (Street or Saint), Ave (Avenue), Blvd (Boulevard), Dr (Drive), Expy (Expressway)\n",
    "#### Pkwy (Parkway), Pl(Place), Rd (Road), TER (Terrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the abbreviation contained in the abbrev_errors dataframe\n",
    "def findabbrev(misspelled):\n",
    "    list2 =['ST', 'ST.','AVE', 'BLVD','DR', 'EXPY', 'PKWY', 'PL','RD', \"TER\" ]\n",
    "    abbrevlist=[]\n",
    "    for name in misspelled:\n",
    "        name = name.upper()\n",
    "        if name in list2:\n",
    "            abbrevlist.append(name)\n",
    "    return abbrevlist\n",
    "\n",
    "#Create 'abbrev_errors' dataframe with data that contains abbreviations\n",
    "#Regex checks if word is by itself, '(?i)' makes the search case insensitive\n",
    "abbrev_errors = df[df['Location'].str.contains(r\"(?i)\\bSt\\b|\\bAve\\b|\\bBlvd\\b|\\bDr\\b|\\bExpy\\b|\\bPkwy\\b|\\bPl\\b|\\bRd\\b|\\bTer\\b\")== True]\n",
    "abbrev_errors['Abbreviation'] = abbrev_errors['Location'].str.split().apply(findabbrev)\n",
    "abbrev_errors['Error']= 'Contains abbreviation:  ' + abbrev_errors['Abbreviation'].astype(str)\n",
    "abbrev_errors.drop(columns =['Abbreviation'], axis=1, inplace=True)\n",
    "\n",
    "abbrev_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ff498",
   "metadata": {},
   "source": [
    "---\n",
    "## Check Location Column for Street Spelling\n",
    "#### Prepping the data for Error Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove missing rows\n",
    "LocationSpellingErrors = df.dropna(subset = ['Location'])\n",
    "\n",
    "#Replace special characters with whitespace in order to extract words\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace('(',' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(')',' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace('-',' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(',',' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(\"â€™\",' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(\"'\",' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(\"/\",' ', regex=True)\n",
    "LocationSpellingErrors['Location'] = LocationSpellingErrors['Location'].str.replace(\".\",' ', regex=True)\n",
    "\n",
    "#Split Location Column into Substrings\n",
    "LocationSpellingErrors['Split_words'] = LocationSpellingErrors['Location'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store rows with data type error in 'LocationSpellingErrors' dataframe\n",
    "LocationTypeError = LocationSpellingErrors[LocationSpellingErrors['Split_words'].isna()]\n",
    "LocationTypeError['Error']= 'Location entry not valid'\n",
    "LocationTypeError.drop(columns =['Split_words'], axis=1, inplace=True)\n",
    "LocationSpellingErrors = LocationSpellingErrors.dropna(subset = ['Split_words'])\n",
    "\n",
    "#Store rows with insufficient words in 'LocationLengthError' dataframe\n",
    "#Column contains less than 3 words\n",
    "LocationLengthError = LocationSpellingErrors[LocationSpellingErrors['Split_words'].map(lambda d: len(d)) < 4]\n",
    "LocationLengthError['Error']= 'Location entry not complete'\n",
    "LocationLengthError.drop(columns =['Split_words'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PySpellChecker library to find misspelt words\n",
    "def incorrectlist(stlist):\n",
    "    return spell.unknown(stlist)\n",
    "\n",
    "# Use PySpellChecker library to find potential corrections to misspelt words\n",
    "def correctlist(misspelled):\n",
    "    correctwords=[]\n",
    "    for word in misspelled:\n",
    "        correctwords.append(spell.correction(word))\n",
    "        return correctwords\n",
    "\n",
    "\n",
    "LocationSpellingErrors['Incorrect Words'] = LocationSpellingErrors['Split_words'].apply(incorrectlist).tolist()\n",
    "LocationSpellingErrors = LocationSpellingErrors[LocationSpellingErrors['Incorrect Words'].map(lambda d: len(d)) > 0]\n",
    "LocationSpellingErrors['Potential word'] = LocationSpellingErrors['Incorrect Words'].apply(correctlist).tolist()\n",
    "LocationSpellingErrors[\"Error\"] = \"Location Spelling Error: \" + LocationSpellingErrors['Incorrect Words'].astype(str)+ '\\n' + \"Did you mean: \" + LocationSpellingErrors['Potential word'].astype(str) + '?'\n",
    "LocationSpellingErrors.drop(columns =['Split_words', 'Incorrect Words','Potential word'], axis=1, inplace=True)\n",
    "print(\"Location Spelling Errors\")\n",
    "LocationSpellingErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8a3d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Full Error Log\n",
    "### Errors are also exported in an excel file in the project directory\n",
    "#### You can remove a specific error check by deleting it from the 'frames' list below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37700331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all error dfs, comment out any errors you want to exlcude from final error log\n",
    "frames = [null_errors, \n",
    "          duplicate_data, \n",
    "          borough_errors, \n",
    "          date_errors, \n",
    "          LocationTypeError,\n",
    "          LocationLengthError, \n",
    "          LocationSpellingErrors, \n",
    "          abbrev_errors]\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "# Sort errors by row index\n",
    "result.sort_index(inplace=True)\n",
    "#Label row\n",
    "result.index.rename('Row', inplace=True)\n",
    "\n",
    "\n",
    "if len(result.index) == 0:\n",
    "    print('No Errors Found')\n",
    "else:\n",
    "#     Restore values of original dataframe that may have been converted to 'NA'\n",
    "    result[\"Location\"] = df['Location']\n",
    "    result[\"Borough\"] = df['Borough']\n",
    "    result[\"Date Installed\"] = df['Date Installed']\n",
    "    print(str(len(result.index)) +' Errors Found')\n",
    "    display( HTML( result.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
    "#     Export Errors in an excel file\n",
    "    result.to_excel('errors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d612493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
